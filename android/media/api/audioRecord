/*
 创建AudioRecord

*/
MediaRecorder{ //数据源
- DEFAULT 
- MIC                //microphone
- REMOTE_SUBMIX      //远程设备(wifi显示器),播放数据也会到远程设备
- UNPROCESSED
- VOICE_CALL         //uplink downlink数据
- VOICE_COMMUNICATION //语音通话voip
- VOICE_DOWNLINK
- VOICE_RECOGNITION
- VOICE_UPLINK
}

AudioRecord recorder = new AudioRecord.Builder()
         .setAudioSource(MediaRecorder.AudioSource.VOICE_COMMUNICATION)
         .setAudioFormat(new AudioFormat.Builder()
                 .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
                 .setSampleRate(32000)
                 .setChannelMask(AudioFormat.CHANNEL_IN_MONO)
                 .build())
         .setBufferSize(2*minBuffSize)
         .build();
-->new AudioRecord(mAttributes, mFormat, mBufferSizeInBytes, mSessionId)-->native_setup
-->android_media_AudioRecord_setup{
- lpRecorder = new AudioRecord@AudioRecord.cpp
- lpRecorder->set(sampleRateInHertz,format,localChanMask,recorderCallback)
}@android_media_AudioRecord.cpp

//获取最小buffer.大小和实际codec缓存大小相关..一帧为一次采样
int getMinBufferSize (int sampleRateInHz, int channelConfig, int audioFormat)
-->native_get_min_buff_size-->android_media_AudioRecord_get_min_buff_size{
- AudioRecord::getMinFrameCount(&frameCount){//获取最小帧数
	- AudioSystem::getInputBufferSize
	- frameCount*2 //将帧数翻倍返回..为了交替使用
	}
- return frameCount * channelCount * audio_bytes_per_sample(format)// 帧转换bytes
}

//开始当前线程AudioRecordThread,获取flinger端接口mAudioRecord
AudioRecord::AudioRecord-->set(audio_source_t inputSource, uint32_t sampleRate, audio_format_t format,
        audio_channel_mask_t channelMask,callback_t cbf){
- mReqFrameCount //根据参数计算帧数
- mCbf = cbf不为空{
	- mAudioRecordThread = new AudioRecordThread(*this,threadCanCallJava){
		- mReceiver(receiver)
		}
	- mAudioRecordThread->run
	}
  //AudioFlinger端打开录音线程
- openRecord_l{
	  //创建RecordThread
	- AudioSystem::getInputForAttr(根据采样率等参数，创建属性)-->aps->getInputForAttr
		AudioPolicyManager::getInputForAttr{//获取流
		- getDeviceAndMixForInputSource-->getDeviceForInputSource//获取input设备
			-->mEngine->getDeviceForInputSource
		- config //设置config 采样率，格式，通道
		- mInputs中查找可用的input，若找到直接返回（实现多应用同时录音）
		- mpClientInterface->openInput(config)-->AudioFlinger::openInput-->openInput_l
		-
		}
	- size_t frameCount = mReqFrameCount
	  //创建RecordTrack
	- sp<IAudioRecord> mAudioRecord = audioFlinger->openRecord(input,mSampleRate,mChannelMask,frameCount,iMem,bufferMem){
		- iMem  //cblk
		- bufferMem //flinger端mBuffer地址
		}@AudioFlinger.cpp //
	- void *iMemPointer = iMem->pointer() //IMemory->pointer获取IMemoryHeap,获取地址
	- audio_track_cblk_t* cblk = static_cast<audio_track_cblk_t*>(iMemPointer) //第一部分为回调
	- buffers = cblk + 1 //buffer位置随后
	- mCblkMemory = iMem 
	- mBufferMemory = bufferMem
	  //创建proxy，用来读取数据
	- mProxy = new AudioRecordClientProxy(cblk, buffers, mFrameCount, mFrameSize){
		- ClientProxy(audio_track_cblk_t* cblk, void *buffers)
		}@AudioTrackShared.h 	
	}
}@AudioRecord.cpp


//处理数据
AudioRecord::AudioRecordThread::threadLoop(){
- mMyCond.wait(mMyLock)
- mReceiver.processAudioBuffer()-->processAudioBuffer{

} 
}@AudioRecord.cpp


/*start */
startRecording@AudioRecord.java-->native_start-->android_media_AudioRecord_start-->lpRecorder->start
@android_media_AudioRecord.cpp-->
start{
- AudioSystem::setParameters(audio_io_handle_t(0) , "record_bypass=1") //googlequicksearchbox 设置bypass
- mProxy->flush()
- status = mAudioRecord->start(event, triggerSession)
- 启动失败,恢复录音,restoreRecord_l("start")
-  if (status != NO_ERROR){AudioSystem::setParameters(audio_io_handle_t(0) , "record_bypass=0")}
   else{
	- mAudioRecordThread.resume
	}	
}@AudioRecord.cpp



/*read
 read数据,读取数据拷贝到 buffer中
*/

read@AudioRecord.java-->native_read_in_short_array(/*byte,short,float数据格式不同*/)-->
android_media_AudioRecord_readInArray-->lpRecorder->read@android_media_AudioRecord.cpp-->
read(buffer,size){
  //通过AudioRecordClientProxy获取数据,装入audioBuffer
- Buffer audioBuffer  
- obtainBuffer(&audioBuffer,const struct timespec )
	-->obtainBuffer{
	- sp<AudioRecordClientProxy> proxy = mProxy
	- sp<IMemory> iMem = mCblkMemory
	- sp<IMemory> bufferMem = mBufferMemory
	- proxy->obtainBuffer(&buffer, requested)-->ClientProxy::obtainBuffer()@AudioTrackShared.cpp
	}
  //拷贝到用户buffer中
- memcpy(buffer, audioBuffer.i8)
}@AudioRecord.cpp


/*stop */
AudioRecord::stop{
- mProxy->interrupt()
- mAudioRecord->stop()
- mAudioRecordThread->pause
- AudioSystem::setParameters(audio_io_handle_t(0) , "record_bypass=0") //googlequicksearchbox
}@AudioRecord.cpp


frameworks/base/media/java/android/media/AudioRecord.java
frameworks/base/core/jni/android_media_AudioRecord.cpp
frameworks/av/media/libaudioclient/AudioRecord.cpp
frameworks/base/media/java/android/media/MediaRecorder.java
frameworks/av/media/libaudioclient/AudioTrackShared.cpp
